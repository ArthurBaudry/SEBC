### B4 is used to calculate the number of maps and reduce, those numbers are defined by the the minimum value between mapreduce.map.memory.mb, mapreduce.map.cpu.vcores which mean that we try to set the numbers of default reducers and mappers by the resources available. A mapper or reducer should at least have 2Gb of memory and 1 vcore to run properly so we take the minimum value of vcores to run a job. 
If the servers we are running on are very powerful (meaning that the vcores and memory value are higher than the product of nodes and workload) and the workload we are expecting is quite low (say 1) then it makes sense not to adapt those settings with a factor of the number of nodes * the workload to be sure that we will not oversize jobs and that many can run concurrently. 
On the contrary if the resources are lower than the workload factor * number of nodes (say 4, where the number of nodes is used here to make sure that we spread accross the cluster that workload) then we should stick to the resources available on each node not to have one job using all the resources available